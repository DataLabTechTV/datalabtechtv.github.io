<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=false><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Data Lakehouse with dbt and DuckLake &#183; Data Lab Tech TV</title>
<meta name=title content="Data Lakehouse with dbt and DuckLake &#183; Data Lab Tech TV"><meta name=description content="Learn how to run your ETL pipelines on top of dbt, DuckDB and DuckLake, and get to know data lab."><meta name=keywords content="duckdb,ducklake,dbt,minio,etl,video,"><link rel=canonical href=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/><link type=text/css rel=stylesheet href=/css/main.bundle.min.36c3cd7950e4533fa7da3150d972e3edf34d07f83c0264ff04cad0969dfdb3b8a7065b0ed6c730c6d34a7bad516cfc6f6a5917ab1fdb10b25f481f8a17b54c16.css integrity="sha512-NsPNeVDkUz+n2jFQ2XLj7fNNB/g8AmT/BMrQlp39s7inBlsO1scwxtNKe61RbPxvalkXqx/bELJfSB+KF7VMFg=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.52b8d61b061c90a738102a0eac69eaa1479fdf5de882a0b0741d7515240617156a6c4477fcc91f9c962062804fe62d2932bb9f57d0aded208c762c2e1ed2e202.js integrity="sha512-UrjWGwYckKc4ECoOrGnqoUef313ogqCwdB11FSQGFxVqbER3/MkfnJYgYoBP5i0pMrufV9Ct7SCMdiwuHtLiAg==" data-copy=Copy data-copied=Copied></script><script src=/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj+Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/"><meta property="og:site_name" content="Data Lab Tech TV"><meta property="og:title" content="Data Lakehouse with dbt and DuckLake"><meta property="og:description" content="Learn how to run your ETL pipelines on top of dbt, DuckDB and DuckLake, and get to know data lab."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-24T12:00:00+01:00"><meta property="article:modified_time" content="2025-06-24T12:00:00+01:00"><meta property="article:tag" content="Duckdb"><meta property="article:tag" content="Ducklake"><meta property="article:tag" content="Dbt"><meta property="article:tag" content="Minio"><meta property="article:tag" content="Etl"><meta property="article:tag" content="Video"><meta property="og:image" content="https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/feature.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/feature.jpeg"><meta name=twitter:title content="Data Lakehouse with dbt and DuckLake"><meta name=twitter:description content="Learn how to run your ETL pipelines on top of dbt, DuckDB and DuckLake, and get to know data lab."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"Data Lakehouse with dbt and DuckLake","headline":"Data Lakehouse with dbt and DuckLake","description":"Learn how to run your ETL pipelines on top of dbt, DuckDB and DuckLake, and get to know data lab.","abstract":"Summary # Now that you can use DuckDB to power your data lakehouse through DuckLake, you\u0026rsquo;ll also save space on snapshots due to the ability to reference parts of parquet files (yes, you can keep all old versions, with little impact to storage), and you\u0026rsquo;ll get improved performance for small change operations due to data inlining, which lets data be stored directly within the metadata database (SQLite, PostgreSQL, etc.","inLanguage":"en","url":"https:\/\/datalabtechtv.com\/posts\/data-lakehouse-dbt-ducklake\/","author":{"@type":"Person","name":"Data Lab Tech"},"copyrightYear":"2025","dateCreated":"2025-06-24T12:00:00\u002b01:00","datePublished":"2025-06-24T12:00:00\u002b01:00","dateModified":"2025-06-24T12:00:00\u002b01:00","keywords":["duckdb","ducklake","dbt","minio","etl","video"],"mainEntityOfPage":"true","wordCount":"3130"}]</script><meta name=author content="Data Lab Tech"><link href=https://youtube.com/@DataLabTechTV rel=me><link href=https://bsky.app/profile/datalabtechtv.com rel=me><link href=https://github.com/DataLabTechTV rel=me><link href=https://discord.gg/6xpe827ANZ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQTLJTJJ7T"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("consent","default",{analytics_storage:"denied",ad_storage:"denied"}),gtag("js",new Date),gtag("config","G-VQTLJTJJ7T",{anonymize_ip:!0,allow_google_signals:!1})</script><script>MathJax={tex:{inlineMath:[["$","$"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js></script><style>.medium-zoom-overlay{background:rgba(0,0,0,.9)!important;z-index:100}</style><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 min-h-[130px] opacity-65 pl-[24px] pr-[24px] bg-gradient-to-b from-neutral from-60% dark:from-neutral-800 to-transparent mix-blend-normal" style=z-index:80></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div><a href=/ class=flex><span class=sr-only>Data Lab Tech TV</span>
<img src=/img/logo.png width=450 height=450 class="logo max-h-[5rem] max-w-[5rem] object-scale-down object-left nozoom" alt="Data Lab Tech TV"></a></div><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Data Lab Tech TV</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Blog</p></a><a href=https://youtube.com/@DataLabTechTV target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg></span></span><p class="text-base font-medium" title>YouTube</p></a><a href=https://bsky.app/profile/datalabtechtv.com target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg></span></span><p class="text-base font-medium" title>Bluesky</p></a><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Categories
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/categories/data-science/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Data Science</p></a><a href=/categories/data-engineering/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Data Engineering</p></a><a href=/categories/mlops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>MLOps</p></a><a href=/categories/devops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>DevOps</p></a><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Software Engineering</p></a><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Philosophy of Technology</p></a></div></div></div></div><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Blog</p></a></li><li class=mt-1><a href=https://youtube.com/@DataLabTechTV target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg></span></div><p class="text-bg font-bg" title>YouTube</p></a></li><li class=mt-1><a href=https://bsky.app/profile/datalabtechtv.com target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg></span></div><p class="text-bg font-bg" title>Bluesky</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Categories</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/categories/data-science/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Data Science</p></a></li><li class=mt-1><a href=/categories/data-engineering/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Data Engineering</p></a></li><li class=mt-1><a href=/categories/mlops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>MLOps</p></a></li><li class=mt-1><a href=/categories/devops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>DevOps</p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Software Engineering</p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Philosophy of Technology</p></a></li><li class=mb-2></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/img/background_hu5250322968290309648.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-30 dark:opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Data Lakehouse with dbt and DuckLake</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-06-24T12:00:00+01:00>24 June 2025</time><span class="px-2 text-primary-500">&#183;</span><span>3130 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">15 mins</span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/categories/data-engineering/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Data Engineering
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/duckdb/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Duckdb
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/ducklake/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Ducklake
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/dbt/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Dbt
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/minio/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Minio
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/etl/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Etl
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/video/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Video</span></span></span></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#summary>Summary</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#storage-layout>Storage Layout</a></li></ul></li><li><a href=#tech-stack>Tech Stack</a><ul><li><a href=#minio>MinIO</a></li><li><a href=#duckdb-and-ducklake>DuckDB and DuckLake</a></li><li><a href=#dbt>dbt</a></li></ul></li><li><a href=#operations>Operations</a><ul><li><a href=#ingestion>Ingestion</a></li><li><a href=#transformation>Transformation</a></li><li><a href=#export>Export</a></li></ul></li><li><a href=#duckdb-highlights>DuckDB Highlights</a><ul><li><a href=#handling-duckdb-minio-secret>Handling DuckDB MinIO Secret</a></li><li><a href=#useful-list-functions>Useful List Functions</a></li><li><a href=#abnormally-slow-json-parsing>Abnormally Slow JSON Parsing</a><ul><li><a href=#first-proposed-solution>First Proposed Solution</a></li><li><a href=#second-proposed-working-solution>Second Proposed (Working) Solution</a></li><li><a href=#third-proposed-creative-solution>Third Proposed (Creative) Solution</a></li></ul></li><li><a href=#duckdb-and-ducklake-wishlist>DuckDB and DuckLake Wishlist</a><ul><li><a href=#1-externally-loadable-parquet-files>1. Externally Loadable Parquet Files</a></li><li><a href=#2-hierarchical-schemas>2. Hierarchical Schemas</a></li><li><a href=#3-sequences-in-ducklake>3. Sequences in DuckLake</a></li></ul></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#summary>Summary</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#storage-layout>Storage Layout</a></li></ul></li><li><a href=#tech-stack>Tech Stack</a><ul><li><a href=#minio>MinIO</a></li><li><a href=#duckdb-and-ducklake>DuckDB and DuckLake</a></li><li><a href=#dbt>dbt</a></li></ul></li><li><a href=#operations>Operations</a><ul><li><a href=#ingestion>Ingestion</a></li><li><a href=#transformation>Transformation</a></li><li><a href=#export>Export</a></li></ul></li><li><a href=#duckdb-highlights>DuckDB Highlights</a><ul><li><a href=#handling-duckdb-minio-secret>Handling DuckDB MinIO Secret</a></li><li><a href=#useful-list-functions>Useful List Functions</a></li><li><a href=#abnormally-slow-json-parsing>Abnormally Slow JSON Parsing</a><ul><li><a href=#first-proposed-solution>First Proposed Solution</a></li><li><a href=#second-proposed-working-solution>Second Proposed (Working) Solution</a></li><li><a href=#third-proposed-creative-solution>Third Proposed (Creative) Solution</a></li></ul></li><li><a href=#duckdb-and-ducklake-wishlist>DuckDB and DuckLake Wishlist</a><ul><li><a href=#1-externally-loadable-parquet-files>1. Externally Loadable Parquet Files</a></li><li><a href=#2-hierarchical-schemas>2. Hierarchical Schemas</a></li><li><a href=#3-sequences-in-ducklake>3. Sequences in DuckLake</a></li></ul></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><h2 class="relative group">Summary<div id=summary class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#summary aria-label=Anchor>#</a></span></h2><p>Now that you can use <a href=https://duckdb.org/ target=_blank>DuckDB</a> to power your data lakehouse through <a href=https://ducklake.select/ target=_blank>DuckLake</a>, you&rsquo;ll also save space on snapshots due to the ability to reference parts of parquet files (yes, you can keep all old versions, with little impact to storage), and you&rsquo;ll get improved performance for small change operations due to data inlining, which lets data be stored directly within the metadata database (<a href=https://www.sqlite.org/ target=_blank>SQLite</a>, <a href=https://www.postgresql.org/ target=_blank>PostgreSQL</a>, etc.).</p><p>With a little help from <a href=https://docs.getdbt.com/ target=_blank>dbt</a> and an <a href=https://github.com/duckdb/dbt-duckdb/issues/564 target=_blank>unreleased branch</a> of <a href=https://github.com/duckdb/dbt-duckdb target=_blank>dbt-duckdb</a> adapter, we were able to design a data lakehouse strategy, covering data ingestion, transformation, and exporting, almost exclusively based on SQL!</p><p>This project is available as open source on GitHub, at <a href=https://github.com/DataLabTechTV/datalab target=_blank>DataLabTechTV/datalab</a>, and the <code>README</code> will cover most of the details you need to understand it and get it running. In this blog post, we cover some of the most interesting components or issues, and provide a few comments about the whole process. You can also see data lab in action, and learn more about it, by watching the video below!</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;max-width:100%><iframe src="https://www.youtube.com/embed/zn69Q7FiFfo?si=hUoNsb3bioUR20J6" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%>></iframe></div><h2 class="relative group">Architecture<div id=architecture class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#architecture aria-label=Anchor>#</a></span></h2><p>Here&rsquo;s an overview of a Data Lab workflow to retrieve and organize a dataset (<code>ingest</code>), transform it into structured tables tracked by DuckLake (<code>transform</code>), and export them for external use (<code>export</code>):</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./datalab-architecture.png alt="Data Lab Architecture"></figure></p><h3 class="relative group">Storage Layout<div id=storage-layout class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#storage-layout aria-label=Anchor>#</a></span></h3><p>Let&rsquo;s begin with the storage layout. We use an S3 compatible object store (MinIO), but you could store your files locally as well (not supported by Data Lab, but easy to implement, as DuckLake supports it).</p><pre tabindex=0><code>s3://lakehouse/
├── backups/
│   └── catalog/
│       ├── YYYY_MM_DD/
│       │   └── HH_mm_SS_sss/
│       │       ├── engine.duckdb
│       │       ├── stage.sqlite
│       │       └── marts/*.sqlite
│       └── manifest.json
├── raw/
│   └── &lt;dataset-name&gt;/
│       ├── YYYY_MM_DD/
│       │   └── HH_mm_SS_sss/
│       │       ├── *.csv
│       │       ├── *.json
│       │       └── *.parquet
│       └── manifest.json
├── stage/
│   └── ducklake-*.parquet
├── marts/
│   └── &lt;domain&gt;/
│           └── ducklake-*.parquet
└── exports/
    └── &lt;domain&gt;/
        └── &lt;dataset-name&gt;/
            ├── YYYY_MM_DD/
            │   └── HH_mm_SS_sss/
            │       ├── *.csv
            │       ├── *.json
            │       └── *.parquet
            └── manifest.json
</code></pre><p>The directory structure above contains:</p><ul><li><code>raw/</code>, which is where you drop your datasets, as they come (usually uncompressed, e.g., if it&rsquo;s a zip file), and you can do this either manually or exclusively via the CLI.</li><li><code>stage/</code> is where parquet files for DuckLake are stored for intermediate transformations.</li><li><code>marts/</code> contains a subdirectory per data mart—I set up mine based on types of data (e.g., <code>graphs</code>) or relevant subjects I&rsquo;m exploring (e.g., <code>economics</code>), but the classical setup is by company department (this shouldn&rsquo;t be your case, as this is not production-ready, it&rsquo;s a lab).</li><li><code>exports/</code> contains exported datasets, usually in parquet format (the only one supported by Data Lab right now), ready to be used or loaded elsewhere.</li><li><code>backups/</code> contains snapshots of the catalog databases, including the DuckDB engine DB and the SQLite DuckLake metadata DBs.</li></ul><p>In some cases, you&rsquo;ll find a path containing a directory representing a date and a subdirectory representing a time—this is the timestamp from when the associated operation was started. We call these &lsquo;dated directories&rsquo;. Each dated directory contains a <code>manifest.json</code> with the dataset name (or snapshot name, for backups), along with the S3 path with the location of the latest version of that dataset.</p><h2 class="relative group">Tech Stack<div id=tech-stack class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tech-stack aria-label=Anchor>#</a></span></h2><h3 class="relative group">MinIO<div id=minio class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#minio aria-label=Anchor>#</a></span></h3><p>We used MinIO, but you can use any S3-compatible object storage. If you&rsquo;re using MinIO and are having trouble connecting, make sure that your <code>S3_REGION</code> matches the MinIO region. You might have to setup a custom region (e.g. <code>eu-west-1</code>) via the Web UI under <code>Configurations → Region</code>.</p><p>Unfortunately, that feature, along with most features for the Community Edition of MinIO, was <a href=https://biggo.com/news/202505261334_MinIO_Removes_Web_UI_Features target=_blank>recently scraped</a>—yes, sadly this includes users, groups, and policies as well.</p><p>We will soon research other viable S3-compatible object storage alternatives, perhaps in the neighborhood of <a href=https://github.com/seaweedfs/seaweedfs target=_blank>SeaweedFS</a>.</p><h3 class="relative group">DuckDB and DuckLake<div id=duckdb-and-ducklake class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#duckdb-and-ducklake aria-label=Anchor>#</a></span></h3><p>While MinIO provides storage, DuckDB provides compute (we call it the &ldquo;engine&rdquo;), and DuckLake provides a catalog layer to manage metadata and external tables, tracking changes and offering snapshots, schema evolution, and time travel.</p><h3 class="relative group">dbt<div id=dbt class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#dbt aria-label=Anchor>#</a></span></h3><p>Tools like dbt (data-build-tool) appear once in a lifetime—much like DuckDB.</p><blockquote><p>❓ Did you know that&mldr;</p><p>dbt is lower case—like sushi chefs that don&rsquo;t like you to use a fork, the
community also dislikes it when you wrongly spell dbt in upper case.</p></blockquote><p>dbt is for SQL templating and organization (models), and data documentation and testing (schemas). It provides a few configuration files to help you link up to external data sources as well, but, overall, this is it. Beautifully simple, yet extremely useful. Truly a gem!</p><p>Since dbt provides multiple adapters, we were able to use the <code>dbt-duckdb</code> adapter and, through an unreleased branch, connect to our DuckLake catalogs via DuckDB. We then used pure DuckDB SQL queries to extract our data from the S3 ingestion bucket (<code>raw/</code>) and transform it into usable structured tables (<code>stage/</code> and <code>marts/</code>).</p><h2 class="relative group">Operations<div id=operations class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#operations aria-label=Anchor>#</a></span></h2><p>Below is an overview of the main lakehouse-related operations that Data Lab supports.</p><p>When required, the <code>dlctl</code> CLI tool will read the manifests and export environment variables pointing to the S3 path with the latest version for each dataset. For example, <code>RAW__DEEZER_SOCIAL_NETWORKS__HR__HR_EDGES</code> will point to something like <code>s3://lakehouse/raw/deezer_social_networks/2025_06_11/11_56_29_470/HR/hr_edges.csv</code>, where the key point here is the date, <code>2025-06-11T11:56:29.470</code>, which points to the most recent ingestion of this dataset.</p><p>Both ingestions (<code>raw/</code>) and exports (<code>exports/</code>) can be listed using the CLI:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl ingest ls
</span></span><span class=line><span class=cl>dlctl ingest ls -a
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>dlctl <span class=nb>export</span> ls
</span></span><span class=line><span class=cl>dlctl <span class=nb>export</span> ls -a
</span></span></code></pre></div><p>As well as pruned (i.e., all versions except the last one are deleted, per dataset):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl ingest prune
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>dlctl <span class=nb>export</span> prune
</span></span></code></pre></div><p>Other than that, catalog backups can be created:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Create a backup and update manifest.json accordingly</span>
</span></span><span class=line><span class=cl>dlctl backup create
</span></span></code></pre></div><p>Listed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># List backup root directories</span>
</span></span><span class=line><span class=cl>dlctl backup ls
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># List all backed up files</span>
</span></span><span class=line><span class=cl>dlctl backup ls -a
</span></span></code></pre></div><p>And restored:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Restore the latest catalog snapshot into local/</span>
</span></span><span class=line><span class=cl>dlctl backup restore
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Restore the latest catalog snapshot into /tmp/xpto</span>
</span></span><span class=line><span class=cl><span class=c1># instead of local/</span>
</span></span><span class=line><span class=cl>dlctl backup restore --target /tmp/xpto
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Restore a specific snapshot into local/</span>
</span></span><span class=line><span class=cl>dlctl backup restore --source 2025-06-17T16:24:31.349
</span></span></code></pre></div><h3 class="relative group">Ingestion<div id=ingestion class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ingestion aria-label=Anchor>#</a></span></h3><p>The <code>dlctl ingestion dataset</code> command supports directory structure creation for manual uploads, as well as direct retrieval from Kaggle or Hugging Face.</p><p>This will create a dated directory for dataset <code>snap_facebook_large</code> (snake case is always used):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl ingest dataset --manual <span class=s2>&#34;SNAP Facebook Large&#34;</span>
</span></span></code></pre></div><p>And the following commands will ingest two datasets, from Kaggle and Hugging Face, respectively:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl ingest dataset <span class=s2>&#34;https://www.kaggle.com/datasets/andreagarritano/deezer-social-networks&#34;</span>
</span></span><span class=line><span class=cl>dlctl ingest dataset <span class=s2>&#34;https://huggingface.co/datasets/agusbegue/spotify-artists&#34;</span>
</span></span></code></pre></div><h3 class="relative group">Transformation<div id=transformation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#transformation aria-label=Anchor>#</a></span></h3><p>The <code>dlctl transform</code>, <code>dlctl test</code>, and <code>dlctl docs</code> commands are wrappers for dbt, although parametrization is specific to <code>dlctl</code> (at least for now).</p><p>We can run a specific model (and, therefore, its SQL transformations) as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl transform -m stage.deezer_social_networks
</span></span><span class=line><span class=cl>dlctl transform -m stage.million_song_dataset_spotify_lastfm
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>dlctl transform -m marts.graphs.music_taste.nodes_genres
</span></span></code></pre></div><p>Notice that the first two runs are for schemas (and all of their tables), while the last run is for a specific table, <code>nodes_genres</code>, within the <code>graphs</code> catalog and the <code>music_taste</code> schema, which is organized under the <code>marts/</code> models.</p><p>This is the stage that produces DuckLake catalogs, storing DuckLake managed parquet files under the <code>stage/</code> and <code>marts/</code> S3 directories.</p><p>Downstream/upstream triggering is also supported, using the regular dbt syntax (<code>+</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl transform -m +marts.graphs.music_taste
</span></span></code></pre></div><p>Finally, you can also run all data tests as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl <span class=nb>test</span>
</span></span></code></pre></div><p>And generate and serve model documentation as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl docs generate
</span></span><span class=line><span class=cl>dlctl docs serve
</span></span></code></pre></div><h3 class="relative group">Export<div id=export class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#export aria-label=Anchor>#</a></span></h3><p>In order to be able to use a dataset externally, you first need to export it, from the DuckLake-specific parquet format into a usable format, like parquet (or CSV, or JSON).</p><p>This can be done by running:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>dlctl <span class=nb>export</span> dataset graphs music_taste
</span></span></code></pre></div><p>Where <code>graphs</code> is a data mart catalog and <code>music_taste</code> is the schema. A few specific table exports, with names matching <code>*nodes*</code> and <code>*edges*</code>, will be stored in subdirectories—<code>nodes/</code> and <code>edges/</code> in this case. A similar logic can be added to the export process in the future, for other categorizable tables. Otherwise, files will live directly in the root directory, matching the schema name (e.g., <code>music_taste</code>).</p><h2 class="relative group">DuckDB Highlights<div id=duckdb-highlights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#duckdb-highlights aria-label=Anchor>#</a></span></h2><p>Most of our SQL code was boring, standard stuff, which is not unusual, but there were also a few interesting points that we cover next.</p><h3 class="relative group">Handling DuckDB MinIO Secret<div id=handling-duckdb-minio-secret class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#handling-duckdb-minio-secret aria-label=Anchor>#</a></span></h3><p>Secrets in DuckDB are ephemeral, and exist only for the active session. As such, we store them in a <code>.env</code> file, which we automatically load via <code>dlctl</code>. We also offer a command to create an <code>init.sql</code> file under the <code>local/</code> directory, directly generated from your <code>.env</code> configuration, once you set it up.</p><p>Accordingly, you can access your Data Lakehouse locally by running:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Generate local/init.sql from your .env</span>
</span></span><span class=line><span class=cl>dlctl tools generate-init-sql
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Connect to the data lakehouse</span>
</span></span><span class=line><span class=cl>duckdb -init local/init.sql local/engine.duckdb
</span></span></code></pre></div><h3 class="relative group">Useful List Functions<div id=useful-list-functions class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#useful-list-functions aria-label=Anchor>#</a></span></h3><p>Datasets frequently contain string columns with comma-separated lists of items—in our case, it was tags—so having access to list functions was extremely useful. Here&rsquo;s the transformation that we used:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=n>list_transform</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>string_split</span><span class=p>(</span><span class=n>tags</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;, &#39;</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>tag</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>list_aggregate</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=n>list_transform</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=n>string_split</span><span class=p>(</span><span class=n>tag</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;_&#39;</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=n>tag_word</span><span class=w> </span><span class=o>-&gt;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=n>ucase</span><span class=p>(</span><span class=k>substring</span><span class=p>(</span><span class=n>tag_word</span><span class=p>,</span><span class=w> </span><span class=mi>1</span><span class=p>,</span><span class=w> </span><span class=mi>1</span><span class=p>))</span><span class=w> </span><span class=o>||</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=n>lcase</span><span class=p>(</span><span class=k>substring</span><span class=p>(</span><span class=n>tag_word</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=s1>&#39;string_agg&#39;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=s1>&#39; &#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>tags</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=p>...</span><span class=w>
</span></span></span></code></pre></div><p>Let&rsquo;s go through it.</p><ol><li><code>list_transform</code> will apply a lambda to each tag, given by <code>string_split</code> (we split by comma and space).</li><li><code>list_aggregate</code> just applies <code>string_agg</code> to concatenate all words in a tag with spaces.</li><li>Words are obtained from <code>string_split</code> on underscore, and <code>list_transform</code> is used to convert to title case.</li><li>Title case was achieved by taking the first letter of a word via <code>substring</code> and converting to <code>ucase</code> (upper case). The remaining <code>substring</code> was converted to <code>lcase</code> (lower case)—if not already.</li></ol><p>For step 4, we could have used a Python UDF (user-defined function) which took a <code>str</code> and just returned <code>input.title()</code>, or we could have implemented it fully in Python, taking the original comma-separated string of tags as the argument. There would have been a slight overhead, since C++ is faster than Python, but it would have been perfectly viable for such tiny data.</p><p>Setting up such a function using <code>dbt-duckdb</code> is done on top of the <a href="https://github.com/duckdb/dbt-duckdb?tab=readme-ov-file#writing-your-own-plugins" target=_blank>plugins API</a>, and would look something like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Module: funcs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>duckdb</span> <span class=kn>import</span> <span class=n>DuckDBPyConnection</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dbt.adapters.duckdb.plugins</span> <span class=kn>import</span> <span class=n>BasePlugin</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Title case conversion function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>to_title</span><span class=p>(</span><span class=nb>input</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nb>input</span><span class=o>.</span><span class=n>title</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Data-specific tag parsing function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>parse_tags</span><span class=p>(</span><span class=n>tags</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>t</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;_&#34;</span><span class=p>,</span> <span class=s2>&#34; &#34;</span><span class=p>)</span><span class=o>.</span><span class=n>title</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;, &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Plugin</span><span class=p>(</span><span class=n>BasePlugin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>configure_connection</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>conn</span><span class=p>:</span> <span class=n>DuckDBPyConnection</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	    <span class=c1># Register as UDFs, with the same name, in DuckDB</span>
</span></span><span class=line><span class=cl>        <span class=n>conn</span><span class=o>.</span><span class=n>create_function</span><span class=p>(</span><span class=s2>&#34;to_title&#34;</span><span class=p>,</span> <span class=n>to_title</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>conn</span><span class=o>.</span><span class=n>create_function</span><span class=p>(</span><span class=s2>&#34;parse_tags&#34;</span><span class=p>,</span> <span class=n>parse_tags</span><span class=p>)</span>
</span></span></code></pre></div><p>A reference to this module would need to be added to the <code>duckdb</code> profile config:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yml data-lang=yml><span class=line><span class=cl><span class=nt>transform</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>outputs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>lakehouse</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>duckdb</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=c># ...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>plugins</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>module</span><span class=p>:</span><span class=w> </span><span class=l>funcs</span><span class=w>
</span></span></span></code></pre></div><p>Either way, I would avoid using this unless strictly necessary—if a working implementation exists in pure SQL, it&rsquo;s usually more efficient than Python.</p><h3 class="relative group">Abnormally Slow JSON Parsing<div id=abnormally-slow-json-parsing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#abnormally-slow-json-parsing aria-label=Anchor>#</a></span></h3><p>One of the datasets we ingested and ran transformations for was <a href=https://www.kaggle.com/datasets/andreagarritano/deezer-social-networks target=_blank>andreagarritano/deezer-social-networks</a>, which is found on Kaggle. It contains user data and friendship relationships for three subsets of Deezer users from Croatia (<code>HR</code>), Hungary (<code>HU</code>), and Romania (<code>RO</code>). For each country, there are two files: <code>*_edges.csv</code> and <code>*_genres.json</code>. The genres JSON looks something like this, but unformatted:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;13357&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;Pop&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;11543&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;Dance&#34;</span><span class=p>,</span> <span class=s2>&#34;Pop&#34;</span><span class=p>,</span> <span class=s2>&#34;Rock&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;11540&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;International Pop&#34;</span><span class=p>,</span> <span class=s2>&#34;Jazz&#34;</span><span class=p>,</span> <span class=s2>&#34;Pop&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>	<span class=nt>&#34;11541&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;Rap/Hip Hop&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span></code></pre></div><p>These files were extremely slow to parse in DuckDB. The largest genres JSON file is for Croatia, and is only 4.89 MiB. However, when we tried to load and transform this file using the following query, we got extremely high memory usage (hitting 14 GiB for DuckDB), and abnormally slow response time:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=k>AS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>CAST</span><span class=p>(</span><span class=n>je</span><span class=p>.</span><span class=k>key</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=nb>INTEGER</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>user_id</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>CAST</span><span class=p>(</span><span class=n>je</span><span class=p>.</span><span class=n>value</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>[])</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>genres</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>read_json</span><span class=p>(</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>)</span><span class=w> </span><span class=n>j</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>json_each</span><span class=p>(</span><span class=n>j</span><span class=p>.</span><span class=n>json</span><span class=p>)</span><span class=w> </span><span class=n>je</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><pre tabindex=0><code>Run Time (s): real 638.958 user 837.703249 sys 438.916651
</code></pre><p>That&rsquo;s nearly 14m‼️</p><p>So, we tried to turn the JSON object into JSON lines, using:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>jq <span class=s2>&#34;to_entries[] | {key: .key, value: .value}&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	HR/HR_genres.json &gt;HR/HR_genres.jsonl
</span></span></code></pre></div><p>Which ran in sub-second time, as expected:</p><pre tabindex=0><code>Executed in  481.52 millis    fish           external
   usr time  407.70 millis  596.00 micros  407.10 millis
   sys time   68.76 millis  914.00 micros   67.85 millis
</code></pre><p>Reading <code>HR/HR_genres.jsonl</code> inside DuckDB was then instant and completely RAM-efficient, also as expected:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=k>AS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>CAST</span><span class=p>(</span><span class=n>j</span><span class=p>.</span><span class=k>key</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=nb>INTEGER</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>user_id</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>CAST</span><span class=p>(</span><span class=n>j</span><span class=p>.</span><span class=n>value</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>[])</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>genres</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>read_json</span><span class=p>(</span><span class=s1>&#39;HR/HR_genres.jsonl&#39;</span><span class=p>)</span><span class=w> </span><span class=n>j</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><pre tabindex=0><code>Run Time (s): real 0.082 user 0.106543 sys 0.032145
</code></pre><p>At first, since so much RAM was in use, we thought the query was actually a <code>CROSS JOIN</code> that replicated the whole JSON object for each produced line in the final table, but then we noticed that this is not the case, since the docs mentioned <code>json_each</code> as being a <code>LATERAL JOIN</code> (see <a href=https://duckdb.org/docs/stable/data/json/json_functions#json-table-functions target=_blank>here</a>).</p><p>We also tried several other approaches, like first creating a table with the JSON object preloaded and querying over that, but this changed nothing. Besides parsing and transforming the file outside DuckDB before reading it in SQL, I don&rsquo;t think there was much else we could do here, which was disappointing, as this would mean we&rsquo;d have to add another layer to Data Lab, between ingestion and transformation, that would also do transformation but now in Python.</p><p>I decided in favor of sticking with a pure SQL solution, so we posted a <a href=https://github.com/duckdb/duckdb/discussions/17981 target=_blank>question</a> in the GitHub Discussion for DuckDB, describing the issue, and one of the users was kind enough to debug the problem with us.</p><h4 class="relative group">First Proposed Solution<div id=first-proposed-solution class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#first-proposed-solution aria-label=Anchor>#</a></span></h4><p>The first suggestion was to use one of the following approaches:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=n>read_json</span><span class=p>(</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>,</span><span class=w> </span><span class=n>records</span><span class=o>=</span><span class=k>false</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>unnest</span><span class=p>(</span><span class=n>json_keys</span><span class=p>(</span><span class=n>json</span><span class=p>))</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>user_id</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>unnest</span><span class=p>(</span><span class=n>list_value</span><span class=p>(</span><span class=n>unpack</span><span class=p>(</span><span class=n>columns</span><span class=p>(</span><span class=n>json</span><span class=p>.</span><span class=o>*</span><span class=p>))))</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>genres</span><span class=w>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=n>UNPIVOT</span><span class=w> </span><span class=p>(</span><span class=k>FROM</span><span class=w> </span><span class=n>read_json</span><span class=p>(</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>))</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=o>*</span><span class=w>
</span></span></span></code></pre></div><p>Let&rsquo;s quickly unpack what is going on with these two queries.</p><h5 class="relative group">Query #1<div id=query-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#query-1 aria-label=Anchor>#</a></span></h5><p>Let&rsquo;s start with the first one. First, we call <code>read_json</code> with <code>records=false</code>. By default, <code>records</code> is set to <code>auto</code>. For <code>records=true</code>, each key will become a column with its corresponding value. For <code>records=false</code>, it will either return a <code>map(varchar, varchar[])</code> or a <code>struct</code> with each user ID identified as a field (the latter is what we want to happen here). You can read more about <code>records</code> <a href=https://duckdb.org/docs/stable/data/json/format_settings.html#records-settings target=_blank>here</a>.</p><p>According to the <a href=https://duckdb.org/docs/stable/sql/dialect/friendly_sql#query-features target=_blank>docs</a>, <code>COLUMNS</code> is essentially an expansion on column selection, like <code>j.*, col1, *</code>, but where we can apply filtering by, or manipulate, the column name(s):</p><blockquote><p><code>COLUMNS()</code> expression can be used to execute the same expression on multiple columns:</p><ul><li>with regular expressions</li><li>with <code>EXCLUDE</code> and <code>REPLACE</code></li><li>with lambda functions</li></ul></blockquote><p>For details on <code>COLUMNS()</code>, go <a href=https://duckdb.org/docs/stable/sql/expressions/star.html#columns-expression target=_blank>here</a>.</p><p>Then, <code>UNPACK</code> works essentially like <code>*lst</code> would do in Python (i.e., it will expand the elements of a list into arguments for a function). In this example, the target function is <code>list_value</code>, which takes multiple arguments and returns a list with those arguments.</p><p>Finally, for completion sake, <code>unnest</code> just unwinds a list or array into rows, and <code>json_keys</code> returns the keys in a JSON object.</p><h5 class="relative group">Query #2<div id=query-2 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#query-2 aria-label=Anchor>#</a></span></h5><p>For the second query, we&rsquo;re just reading the JSON object using <code>records=auto</code>, which translates into <code>records=true</code> for the small sample JSON. Then, we are applying <code>UNPIVOT</code> on all columns (the user IDs), so that each becomes a row of user ID and list of genres.</p><p>Docs about <code>UNPIVOT</code> <a href=https://duckdb.org/docs/stable/sql/statements/unpivot target=_blank>here</a>.</p><p>Both Query #1 and Query #2 worked fine for the small example that we provided (same as above), but failed for the larger original file.</p><h4 class="relative group">Second Proposed (Working) Solution<div id=second-proposed-working-solution class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#second-proposed-working-solution aria-label=Anchor>#</a></span></h4><p>We found out that the JSON object was parsed differently from 200 user records onward, and discovered there is a default of <code>map_inference_threshold=200</code> for <code>read_json</code>. For long JSON objects like the one we have, this means that it will stop parsing object keys as structure fields from 200 keys onward, thus returning a <code>map(varchar, varchar[])</code> instead of a <code>struct</code>, making the original query fail.</p><p>Knowing this, the suggestion was to disable the threshold for map inference and run the query:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=n>read_json</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=n>records</span><span class=o>=</span><span class=k>false</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=n>map_inference_threshold</span><span class=o>=-</span><span class=mi>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>unnest</span><span class=p>(</span><span class=n>json_keys</span><span class=p>(</span><span class=n>json</span><span class=p>))</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>user_id</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>unnest</span><span class=p>(</span><span class=n>list_value</span><span class=p>(</span><span class=n>unpack</span><span class=p>(</span><span class=n>columns</span><span class=p>(</span><span class=n>json</span><span class=p>.</span><span class=o>*</span><span class=p>))))</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>genres</span><span class=w>
</span></span></span></code></pre></div><p>This brough down the run time from 14m to 24s, which is a significant speedup, but still extremely slow compared to the sub-second run time we got from first parsing the JSON object via <code>jq</code> to turn it into JSON lines.</p><p>This also made it possible to run the <code>UNPIVOT</code> query, which was even faster, taking only 6s to run:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=n>UNPIVOT</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>FROM</span><span class=w> </span><span class=n>read_json</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>		</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>		</span><span class=n>records</span><span class=o>=</span><span class=k>true</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>		</span><span class=n>map_inference_threshold</span><span class=o>=-</span><span class=mi>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=o>*</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><h4 class="relative group">Third Proposed (Creative) Solution<div id=third-proposed-creative-solution class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#third-proposed-creative-solution aria-label=Anchor>#</a></span></h4><p>Finally, a third solution based on a variable to store the JSON object keys was also proposed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SET</span><span class=w> </span><span class=k>variable</span><span class=w> </span><span class=n>user_ids</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>FROM</span><span class=w> </span><span class=n>read_json_objects</span><span class=p>(</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>SELECT</span><span class=w> </span><span class=n>json_keys</span><span class=p>(</span><span class=n>json</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w> </span><span class=n>read_json_objects</span><span class=p>(</span><span class=s1>&#39;HR/HR_genres.json&#39;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>unnest</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>getvariable</span><span class=p>(</span><span class=s1>&#39;user_ids&#39;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>)::</span><span class=nb>INTEGER</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>user_id</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>unnest</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>		</span><span class=n>json_extract</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=n>json</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=n>getvariable</span><span class=p>(</span><span class=s1>&#39;user_ids&#39;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	    </span><span class=p>)::</span><span class=nb>VARCHAR</span><span class=p>[]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>genres</span><span class=w>
</span></span></span></code></pre></div><p>We find it interesting that such a solution design is possible in DuckDB. Regardless, this version was less efficient than the <code>UNPIVOT</code> query on the second solution, so we went with that.</p><p>The question remains. If the best solution takes 6s to run for a 5 MiB file, is this something that we might need to address in DuckDB, specially when the same process can run in milliseconds with a little command line magic?</p><h3 class="relative group">DuckDB and DuckLake Wishlist<div id=duckdb-and-ducklake-wishlist class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#duckdb-and-ducklake-wishlist aria-label=Anchor>#</a></span></h3><p>While we were working with DuckDB and DuckLake, we created a bit of a wishlist, which we share with you below.</p><h4 class="relative group">1. Externally Loadable Parquet Files<div id=1-externally-loadable-parquet-files class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#1-externally-loadable-parquet-files aria-label=Anchor>#</a></span></h4><p>Currently, using data from DuckLake tables externally requires exporting (e.g., to parquet). Maybe there isn&rsquo;t a better solution, but it also defies the purpose of a data lakehouse, as data won&rsquo;t be ready to use without a DuckLake adapter on target tools, which doesn&rsquo;t seem reasonable to expect any time soon.</p><p>It&rsquo;s not clear whether an DuckLake parquet file can be directly read by external processes, but it seems unlikely to be the case. Whether this is desirable, or a solid design choice, it is surely up for discussion, but, if we&rsquo;re building on top of external storage, shouldn&rsquo;t the stored files be ready to use directly?</p><p>If we follow that direction, then there is no clear way to match external files to the tables in DuckLake, as the current naming schema is not designed for identifying which parquet files are which.</p><h4 class="relative group">2. Hierarchical Schemas<div id=2-hierarchical-schemas class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#2-hierarchical-schemas aria-label=Anchor>#</a></span></h4><p>Hierarchical schemas would be useful (e.g., <code>marts.graphs.music.nodes</code>), as this comes up a lot.</p><p>It is how dbt sets up its model logic—they use an <code>_</code> for different levels—and it is also the way disk storage works (i.e., directories are hierarchical), and the natural way to organize data.</p><p>Some teams are even looking into graph-based structures for data cataloging (e.g., <a href=https://netflixtechblog.com/uda-unified-data-architecture-6a6aee261d8d target=_blank>Netflix</a>). Maybe that could be an interesting as a feature for DuckDB and DuckLake, not to mention an additional distinguishing factor.</p><h4 class="relative group">3. Sequences in DuckLake<div id=3-sequences-in-ducklake class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3-sequences-in-ducklake aria-label=Anchor>#</a></span></h4><p>It would be nice to have access to sequences in DuckLake, if that makes sense technically as well. For example, while preparing nodes, generating node IDs could be done using sequences a opposed to something like:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>WITH</span><span class=w> </span><span class=n>other_nodes</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>SELECT</span><span class=w> </span><span class=k>max</span><span class=p>(</span><span class=n>node_id</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>last_node_id</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>	</span><span class=k>FROM</span><span class=w> </span><span class=p>...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w> </span><span class=n>o</span><span class=p>.</span><span class=n>last_node_id</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>row_number</span><span class=p>()</span><span class=w> </span><span class=n>OVER</span><span class=w> </span><span class=p>()</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>node_id</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w> </span><span class=p>...,</span><span class=w> </span><span class=n>other_nodes</span><span class=w> </span><span class=n>o</span><span class=w>
</span></span></span></code></pre></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Data Lab Tech" src=/img/avatar_hu14365428751860151861.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Data Lab Tech</div><div class="text-sm text-neutral-700 dark:text-neutral-400"><a href=https://youtube.com/@DataLabTechTV target=_blank>https://youtube.com/@DataLabTechTV</a></div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://youtube.com/@DataLabTechTV target=_blank aria-label=Youtube rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://bsky.app/profile/datalabtechtv.com target=_blank aria-label=Bluesky rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/DataLabTechTV target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://discord.gg/6xpe827ANZ target=_blank aria-label=Discord rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M524.531 69.836a1.5 1.5.0 00-.764-.7A485.065 485.065.0 00404.081 32.03a1.816 1.816.0 00-1.923.91 337.461 337.461.0 00-14.9 30.6 447.848 447.848.0 00-134.426.0 309.541 309.541.0 00-15.135-30.6 1.89 1.89.0 00-1.924-.91A483.689 483.689.0 00116.085 69.137a1.712 1.712.0 00-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016.0 00.765 1.375A487.666 487.666.0 00176.02 479.918a1.9 1.9.0 002.063-.676A348.2 348.2.0 00208.12 430.4a1.86 1.86.0 00-1.019-2.588 321.173 321.173.0 01-45.868-21.853 1.885 1.885.0 01-.185-3.126c3.082-2.309 6.166-4.711 9.109-7.137a1.819 1.819.0 011.9-.256c96.229 43.917 200.41 43.917 295.5.0a1.812 1.812.0 011.924.233c2.944 2.426 6.027 4.851 9.132 7.16a1.884 1.884.0 01-.162 3.126 301.407 301.407.0 01-45.89 21.83 1.875 1.875.0 00-1 2.611 391.055 391.055.0 0030.014 48.815 1.864 1.864.0 002.063.7A486.048 486.048.0 00610.7 405.729a1.882 1.882.0 00.765-1.352C623.729 277.594 590.933 167.465 524.531 69.836zM222.491 337.58c-28.972.0-52.844-26.587-52.844-59.239S193.056 219.1 222.491 219.1c29.665.0 53.306 26.82 52.843 59.239.0 32.654-23.41 59.241-52.843 59.241zm195.38.0c-28.971.0-52.843-26.587-52.843-59.239S388.437 219.1 417.871 219.1c29.667.0 53.307 26.82 52.844 59.239.0 32.654-23.177 59.241-52.844 59.241z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:mail@datalabtechtv.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></span></a></div></div></div></div><div class=mb-10></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/&amp;title=Data%20Lakehouse%20with%20dbt%20and%20DuckLake" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://bsky.app/intent/compose?text=Data%20Lakehouse%20with%20dbt%20and%20DuckLake+https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/" title="Post on Bluesky" aria-label="Post on Bluesky"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://s2f.kytta.dev/?text=Data%20Lakehouse%20with%20dbt%20and%20DuckLake%20https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/" title aria-label><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48.0.0.0-63.72 28.5-63.72 125.7.0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54.0 01-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://reddit.com/submit/?url=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/&amp;resubmit=true&amp;title=Data%20Lakehouse%20with%20dbt%20and%20DuckLake" title="Submit to Reddit" aria-label="Submit to Reddit"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M201.5 305.5c-13.8.0-24.9-11.1-24.9-24.6.0-13.8 11.1-24.9 24.9-24.9 13.6.0 24.6 11.1 24.6 24.9.0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4.0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7.0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9.0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5.0 52.6 59.2 95.2 132 95.2 73.1.0 132.3-42.6 132.3-95.2.0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6.0-2.2-2.2-6.1-2.2-8.3.0-2.5 2.5-2.5 6.4.0 8.6 22.8 22.8 87.3 22.8 110.2.0 2.5-2.2 2.5-6.1.0-8.6-2.2-2.2-6.1-2.2-8.3.0zm7.7-75c-13.6.0-24.6 11.1-24.6 24.9.0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.1 24.9-24.6.0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer/sharer.php?u=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/&amp;quote=Data%20Lakehouse%20with%20dbt%20and%20DuckLake" title="Share on Facebook" aria-label="Share on Facebook"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/&amp;subject=Data%20Lakehouse%20with%20dbt%20and%20DuckLake" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://api.whatsapp.com/send?text=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/&amp;resubmit=true&amp;title=Data%20Lakehouse%20with%20dbt%20and%20DuckLake" title="Share via WhatsApp" aria-label="Share via WhatsApp"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4.0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3.0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2.0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2.0-101.7 82.8-184.5 184.6-184.5 49.3.0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5.0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8s-14.3 18-17.6 21.8c-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2s-9.7 1.4-14.8 6.9c-5.1 5.6-19.4 19-19.4 46.3.0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://t.me/share/url?url=https://datalabtechtv.com/posts/data-lakehouse-dbt-ducklake/&amp;resubmit=true&amp;title=Data%20Lakehouse%20with%20dbt%20and%20DuckLake" title="Share via Telegram" aria-label="Share via Telegram"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M248 8C111.033 8 0 119.033.0 256S111.033 504 248 504 496 392.967 496 256 384.967 8 248 8zM362.952 176.66c-3.732 39.215-19.881 134.378-28.1 178.3-3.476 18.584-10.322 24.816-16.948 25.425-14.4 1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25 5.342-39.5 3.652-3.793 67.107-61.51 68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608 69.142-14.845 10.194-26.894 9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7 18.45-13.7 108.446-47.248 144.628-62.3c68.872-28.647 83.183-33.623 92.511-33.789 2.052-.034 6.639.474 9.61 2.885a10.452 10.452.0 013.53 6.716A43.765 43.765.0 01362.952 176.66z"/></svg></span></a></section></div><script>var oid="views_posts/data-lakehouse-dbt-ducklake/index.md",oid_likes="likes_posts/data-lakehouse-dbt-ducklake/index.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/posts/postgresql-maximalism/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">PostgreSQL Maximalism</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-05-27T12:00:00+01:00>27 May 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/posts/automate-blog-and-social-media/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Automating Hugo Blog and Social Media with GitHub Actions</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-07-01T12:00:00+01:00>1 July 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 mt-8 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/privacy/ title>Privacy</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/cookies/ title>Cookies</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a id=reset-cookie-options class="decoration-primary-500 flex items-center" href=# title="Reset Cookie Options"><span class=mr-1>🍪</span></a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Data Lab Tech</p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script><script src=/js/search-keybind.min.b0547e1bcfb3922a05d78728999bbd36902e6c52a31b0b1efa373df47c6fa095.js integrity="sha256-sFR+G8+zkioF14comZu9NpAubFKjGwse+jc99HxvoJU=" crossorigin=anonymous></script><script src=/js/cookie-banner.min.010e183607b0d0550c6b0c6cdfee0ef6a8251e4995f06db7c9541c7a847f9751.js integrity="sha256-AQ4YNgew0FUMawxs3+4O9qglHkmV8G23yVQceoR/l1E=" crossorigin=anonymous></script><div id=cookie-spacer class="h-12 hidden"></div><div id=cookie-banner class="fixed inset-x-0 bottom-0 z-[90] hidden"><div class="opacity-90 backdrop-blur-2xl shadow-2xl px-4 py-4 text-sm text-white dark:text-neutral-100"><div class="max-w-[64rem] mx-auto flex flex-wrap items-center justify-between gap-4"><span>We use cookies to enhance your experience.
<a href=/privacy/ class="underline text-blue-300 hover:text-blue-100 ml-1">Learn more</a>.</span><div class="flex gap-4 shrink-0"><button id=cookie-decline class="font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400 cursor-pointer">
Decline
</button>
<button id=cookie-accept class="font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400 cursor-pointer">
Accept</button></div></div></div></div><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
    mermaid.initialize({
        startOnLoad: true,
        theme: 'base',
        flowchart: {
            nodeSpacing: 20,
            rankSpacing: 100,
        },
        themeVariables: {
            fontFamily: 'var(--default-mono-font-family, ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace)',
            fontSize: "1.5em",

            background: '#1e1e1e',
            textColor: '#f8fafc',
            primaryColor: '#0ea5e9',
            primaryTextColor: '#f8fafc',
            lineColor: '#94a3b8',

             

            nodeBorder: '#38bdf8',
            clusterBkg: '#2c3a4a',
            clusterBorder: '#4b5563',

             

            tagLabelFontSize: ".6em",
            commitLabelFontSize: ".6em",

            commitLabelColor: "#f8fafc",
            commitLabelBackground: "#2c3a4a",

            git0: "#0ea5e9",
            git1: "#4b5563",
        }
    });
</script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://datalabtechtv.com/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>