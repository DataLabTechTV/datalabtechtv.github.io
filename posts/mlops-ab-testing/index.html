<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=false><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>MLOps: A/B Testing with MLflow, Kafka, and DuckLake &#183; Data Lab Tech TV</title>
<meta name=title content="MLOps: A/B Testing with MLflow, Kafka, and DuckLake &#183; Data Lab Tech TV"><meta name=description content="Learn how to implement an end-to-end machine learning workflow, from data ingestion, to A/B testing and monitoring, using MLflow, Kafka and DuckLake."><meta name=keywords content="mlflow,ducklake,kafka,monitoring,ab-testing,video,"><link rel=canonical href=https://datalabtechtv.com/posts/mlops-ab-testing/><link type=text/css rel=stylesheet href=/css/main.bundle.min.36c3cd7950e4533fa7da3150d972e3edf34d07f83c0264ff04cad0969dfdb3b8a7065b0ed6c730c6d34a7bad516cfc6f6a5917ab1fdb10b25f481f8a17b54c16.css integrity="sha512-NsPNeVDkUz+n2jFQ2XLj7fNNB/g8AmT/BMrQlp39s7inBlsO1scwxtNKe61RbPxvalkXqx/bELJfSB+KF7VMFg=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.52b8d61b061c90a738102a0eac69eaa1479fdf5de882a0b0741d7515240617156a6c4477fcc91f9c962062804fe62d2932bb9f57d0aded208c762c2e1ed2e202.js integrity="sha512-UrjWGwYckKc4ECoOrGnqoUef313ogqCwdB11FSQGFxVqbER3/MkfnJYgYoBP5i0pMrufV9Ct7SCMdiwuHtLiAg==" data-copy=Copy data-copied=Copied></script><script src=/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj+Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://datalabtechtv.com/posts/mlops-ab-testing/"><meta property="og:site_name" content="Data Lab Tech TV"><meta property="og:title" content="MLOps: A/B Testing with MLflow, Kafka, and DuckLake"><meta property="og:description" content="Learn how to implement an end-to-end machine learning workflow, from data ingestion, to A/B testing and monitoring, using MLflow, Kafka and DuckLake."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-27T17:00:00+01:00"><meta property="article:modified_time" content="2025-08-28T15:57:00+01:00"><meta property="article:tag" content="Mlflow"><meta property="article:tag" content="Ducklake"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Monitoring"><meta property="article:tag" content="Ab-Testing"><meta property="article:tag" content="Video"><meta property="og:image" content="https://datalabtechtv.com/posts/mlops-ab-testing/feature.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://datalabtechtv.com/posts/mlops-ab-testing/feature.jpeg"><meta name=twitter:title content="MLOps: A/B Testing with MLflow, Kafka, and DuckLake"><meta name=twitter:description content="Learn how to implement an end-to-end machine learning workflow, from data ingestion, to A/B testing and monitoring, using MLflow, Kafka and DuckLake."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"MLOps: A\/B Testing with MLflow, Kafka, and DuckLake","headline":"MLOps: A\/B Testing with MLflow, Kafka, and DuckLake","description":"Learn how to implement an end-to-end machine learning workflow, from data ingestion, to A\/B testing and monitoring, using MLflow, Kafka and DuckLake.","abstract":"Summary # Learn how to implement an end-to-end machine learning workflow, from data ingestion, to A\/B testing and monitoring, using MLflow, Kafka and DuckLake.","inLanguage":"en","url":"https:\/\/datalabtechtv.com\/posts\/mlops-ab-testing\/","author":{"@type":"Person","name":"Data Lab Tech"},"copyrightYear":"2025","dateCreated":"2025-08-27T17:00:00\u002b01:00","datePublished":"2025-08-27T17:00:00\u002b01:00","dateModified":"2025-08-28T15:57:00\u002b01:00","keywords":["mlflow","ducklake","kafka","monitoring","ab-testing","video"],"mainEntityOfPage":"true","wordCount":"3845"}]</script><meta name=author content="Data Lab Tech"><link href=https://youtube.com/@DataLabTechTV rel=me><link href=https://bsky.app/profile/datalabtechtv.com rel=me><link href=https://github.com/DataLabTechTV rel=me><link href=https://discord.gg/6xpe827ANZ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-VQTLJTJJ7T"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("consent","default",{analytics_storage:"denied",ad_storage:"denied"}),gtag("js",new Date),gtag("config","G-VQTLJTJJ7T",{anonymize_ip:!0,allow_google_signals:!1})</script><script>MathJax={tex:{inlineMath:[["$","$"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js></script><style>.medium-zoom-overlay{background:rgba(0,0,0,.9)!important;z-index:100}.of-wide{width:150%;margin-left:-25%;height:auto}.of-narrow{width:125%;height:auto}</style><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 min-h-[130px] opacity-65 pl-[24px] pr-[24px] bg-gradient-to-b from-neutral from-60% dark:from-neutral-800 to-transparent mix-blend-normal" style=z-index:80></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div><a href=/ class=flex><span class=sr-only>Data Lab Tech TV</span>
<img src=/img/logo.png width=450 height=450 class="logo max-h-[5rem] max-w-[5rem] object-scale-down object-left nozoom" alt="Data Lab Tech TV"></a></div><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Data Lab Tech TV</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Blog</p></a><a href=https://youtube.com/@DataLabTechTV target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg></span></span><p class="text-base font-medium" title>YouTube</p></a><a href=https://bsky.app/profile/datalabtechtv.com target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg></span></span><p class="text-base font-medium" title>Bluesky</p></a><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Categories
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/categories/data-science/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Data Science</p></a><a href=/categories/data-engineering/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Data Engineering</p></a><a href=/categories/mlops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>MLOps</p></a><a href=/categories/devops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>DevOps</p></a><a href=/categories/software-engineering/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Software Engineering</p></a><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" style=white-space:nowrap title>Philosophy of Technology</p></a></div></div></div></div><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Blog</p></a></li><li class=mt-1><a href=https://youtube.com/@DataLabTechTV target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg></span></div><p class="text-bg font-bg" title>YouTube</p></a></li><li class=mt-1><a href=https://bsky.app/profile/datalabtechtv.com target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg></span></div><p class="text-bg font-bg" title>Bluesky</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Categories</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/categories/data-science/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Data Science</p></a></li><li class=mt-1><a href=/categories/data-engineering/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Data Engineering</p></a></li><li class=mt-1><a href=/categories/mlops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>MLOps</p></a></li><li class=mt-1><a href=/categories/devops/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>DevOps</p></a></li><li class=mt-1><a href=/categories/software-engineering/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Software Engineering</p></a></li><li class=mt-1><a href class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>Philosophy of Technology</p></a></li><li class=mb-2></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/img/background_hu5250322968290309648.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-30 dark:opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">MLOps: A/B Testing with MLflow, Kafka, and DuckLake</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-08-27T17:00:00+01:00>27 August 2025</time><span class="px-2 text-primary-500">&#183;</span><span>3845 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">19 mins</span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/categories/mlops/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">MLOps
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/mlflow/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Mlflow
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/ducklake/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Ducklake
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/kafka/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Kafka
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/monitoring/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Monitoring
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/ab-testing/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Ab-Testing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='return window.open("/tags/video/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Video</span></span></span></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#summary>Summary</a></li><li><a href=#organizational-roles>Organizational Roles</a></li><li><a href=#architecture>Architecture</a></li><li><a href=#orchestration>Orchestration</a></li><li><a href=#training-and-tracking>Training and Tracking</a><ul><li><a href=#mlflow-artifact-storage>MLflow Artifact Storage</a></li></ul></li><li><a href=#evaluation-and-inferencing>Evaluation and Inferencing</a></li><li><a href=#deployment>Deployment</a><ul><li><a href=#mlflow-models>MLflow Models</a></li><li><a href=#custom-api>Custom API</a></li></ul></li><li><a href=#monitoring-strategy>Monitoring Strategy</a><ul><li><a href=#prediction-drift>Prediction Drift</a></li><li><a href=#feature-drift>Feature Drift</a><ul><li><a href=#per-feature>Per Feature</a></li><li><a href=#per-dataset>Per Dataset</a></li></ul></li><li><a href=#estimated-performance>Estimated Performance</a></li><li><a href=#user-feedback>User Feedback</a></li><li><a href=#extending-observability>Extending Observability</a></li></ul></li><li><a href=#simulating-inference-and-feedback>Simulating Inference and Feedback</a></li><li><a href=#ab-testing-results>A/B Testing Results</a><ul><li><a href=#inferences-over-time>Inferences Over Time</a></li><li><a href=#prediction-drift-1>Prediction Drift</a></li><li><a href=#feature-drift-1>Feature Drift</a></li><li><a href=#estimated-performance-1>Estimated Performance</a></li><li><a href=#user-feedback-1>User Feedback</a></li></ul></li><li><a href=#final-remarks>Final Remarks</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#summary>Summary</a></li><li><a href=#organizational-roles>Organizational Roles</a></li><li><a href=#architecture>Architecture</a></li><li><a href=#orchestration>Orchestration</a></li><li><a href=#training-and-tracking>Training and Tracking</a><ul><li><a href=#mlflow-artifact-storage>MLflow Artifact Storage</a></li></ul></li><li><a href=#evaluation-and-inferencing>Evaluation and Inferencing</a></li><li><a href=#deployment>Deployment</a><ul><li><a href=#mlflow-models>MLflow Models</a></li><li><a href=#custom-api>Custom API</a></li></ul></li><li><a href=#monitoring-strategy>Monitoring Strategy</a><ul><li><a href=#prediction-drift>Prediction Drift</a></li><li><a href=#feature-drift>Feature Drift</a><ul><li><a href=#per-feature>Per Feature</a></li><li><a href=#per-dataset>Per Dataset</a></li></ul></li><li><a href=#estimated-performance>Estimated Performance</a></li><li><a href=#user-feedback>User Feedback</a></li><li><a href=#extending-observability>Extending Observability</a></li></ul></li><li><a href=#simulating-inference-and-feedback>Simulating Inference and Feedback</a></li><li><a href=#ab-testing-results>A/B Testing Results</a><ul><li><a href=#inferences-over-time>Inferences Over Time</a></li><li><a href=#prediction-drift-1>Prediction Drift</a></li><li><a href=#feature-drift-1>Feature Drift</a></li><li><a href=#estimated-performance-1>Estimated Performance</a></li><li><a href=#user-feedback-1>User Feedback</a></li></ul></li><li><a href=#final-remarks>Final Remarks</a></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><h2 class="relative group">Summary<div id=summary class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#summary aria-label=Anchor>#</a></span></h2><p>Learn how to implement an end-to-end machine learning workflow, from data ingestion, to A/B testing and monitoring, using MLflow, Kafka and DuckLake. We&rsquo;ll discuss model training and tracking with MLflow, real-world deployment approaches, how to track inference results and feedback in your data lakehouse using Kafka and DuckLake, and how to compute monitoring statistics such as prediction drift, feature drift, or estimated performance, for unlabeled data, as well as taking advantage of user feedback to estimate model error. This should give you the tools you need to build and maintain your own ML lifecycle.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden;max-width:100%><iframe src="https://www.youtube.com/embed/MGuj13NcdjE?si=LCpbSbdgiZcwbIEj" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen style=position:absolute;top:0;left:0;width:100%;height:100%>></iframe></div><h2 class="relative group">Organizational Roles<div id=organizational-roles class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#organizational-roles aria-label=Anchor>#</a></span></h2><p>I&rsquo;ll start with a bit of a comment on organizational roles in a data team, and their responsibilities. This will help clarify a design choice I made in the architecture diagram below.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./ml_engineering_data_science_overlap.png alt="ML Engineering and Data Science Overlap"></figure></p><p>We&rsquo;re considering a team with a Data Engineer, a Data Scientist, and a ML Engineer. As most ops roles, the ML Engineer has responsibilities that overlap with other areas covered by other roles, but these usually have a distinct focus when compared to those other roles.</p><p>For example, both a Data Scientist and a ML Engineer will work with model training and evaluation in some capacity, but the Data Scientist is usually more interested in picking the right algorithm, hyperparameters and features for training, or the right evaluation metrics for the problem at hand, while the ML Engineer is concerned with making sure that these processes can be tracked in a way that models are properly registered and information is easily available to make a decision on the best model and its staging or production readiness.</p><p>Similarly, the Data Engineer also overlaps with the ML Engineer, particularly regarding the data quality aspects of the training and test datasets.</p><h2 class="relative group">Architecture<div id=architecture class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#architecture aria-label=Anchor>#</a></span></h2><p>In the diagram below, we highlight the Data Engineering, Data Science, and ML Engineering responsibilities. In blue, you&rsquo;ll be able to track the training flow, in yellow the evaluation flow, and in green the inference flow. The middle layer is an overview on the data schemas for DuckLake tables and Kafka topics. On the bottom, you&rsquo;ll find the service layer, with the REST API, and the Kafka producers and consumers.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./mlops-e2e-architecture.png alt="MLOps End-to-End Architecture"></figure></p><p>In our implementation, FastAPI was responsible for initializing the Kafka producers and consumers, but in a real-world scenario this would be done separately, each running on their own container.</p><p>Why Kafka and not something else, like gRPC or Redis Pub/Sub? Kafka acts as an event log, so it provides topic replayability, which is great for compliance, but also for debugging. It can also front-face your product in a way that more brokers can be deployed in groups, handling partitioned messages to the same topic, which is a great way to scale up and down as required. The trade-off is that a controller and a single broker will require ~600 MiB of RAM to run, which is usually acceptable, but, depending on your priorities, it might be too much for basic RPC or queuing, and this will only provide replayability as an advantage, but not partitioning or the reliability of multiple brokers.</p><h2 class="relative group">Orchestration<div id=orchestration class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#orchestration aria-label=Anchor>#</a></span></h2><p>Previously, we hadn&rsquo;t implemented any approach for orchestration on <a href=https://github.com/DataLabTechTV/datalab/ target=_blank>datalab</a>, but with the new ML package, this gained more relevance, so we opted to use <a href=https://just.systems/man/en/ target=_blank>just</a> for handling tasks via the command line. This is yet another great tool built in Rust, that mimics the <code>make</code> command, but it&rsquo;s specifically designed for running tasks, as a opposed to building files. Implementing tasks in a <code>Makefile</code> usually requires that those targets are added as dependencies of the <code>.PHONY</code> target, so that <code>make</code> knows they won&rsquo;t produce a file. This would avoid that a task with a name matching an existing file would be skipped due to the file existing and being up-to-date. Instead, when using a <code>justfile</code>, all targets are essentially <code>.PHONY</code>. In addition, since <code>just</code> is a tool specifically designed to run tasks, it also provides several utilities that simplify your life. For example, preloading your existing <code>.env</code> is as easy as adding:</p><pre tabindex=0><code class=language-just data-lang=just>set dotenv-load
</code></pre><p>And while <code>make</code> will run using <code>/bin/sh</code> by default, <code>just</code> will use your login shell by default. Additionally, <code>just</code> also supports positional parameters with default values, and it provides a simple way to list all tasks and their parameters:</p><pre tabindex=0><code class=language-just data-lang=just>just -l
</code></pre><p>A good way to setup your <code>justfile</code> is to use this as your first task:</p><pre tabindex=0><code class=language-just data-lang=just>default:
    just -l
</code></pre><p>The first task is the one that&rsquo;s run by default when invoking <code>just</code> without any arguments. And yes, <code>just</code> can call <code>just</code> from other tasks. For example, we do this:</p><pre tabindex=0><code class=language-just data-lang=just>check-init-sql:
    test -r {{init_sql_path}} || just generate-init-sql
</code></pre><p>It also distinguishes internal variables from environment variables:</p><pre tabindex=0><code class=language-just data-lang=just>engine_db_path := join(local_dir, env_var(&#34;ENGINE_DB&#34;))

check-engine-db:
    test -r {{engine_db_path}}
</code></pre><p>So, if your orchestration needs don&rsquo;t require something like <a href=https://airflow.apache.org/ target=_blank>Apache Airflow</a> or <a href=https://www.prefect.io/ target=_blank>Prefect</a>, and <code>make</code> or shell scripting don&rsquo;t quite do it, you should consider just using <a href=https://just.systems/ target=_blank>just</a>.</p><h2 class="relative group">Training and Tracking<div id=training-and-tracking class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#training-and-tracking aria-label=Anchor>#</a></span></h2><p>As a way to test our workflow, we decided to train a model to classify user-generated text as depression or not depression. For training and testing, we used the <a href=https://huggingface.co/datasets/ShreyaR/DepressionDetection target=_blank>ShreyaR/DepressionDetection</a> dataset from Hugging Face. This was ingested and transformed as usual, using our <a href="https://youtu.be/zn69Q7FiFfo?si=4vDV_nYxjRtujjLV" target=_blank>dbt and DuckLake workflow</a>.</p><p>We then trained four models, combining two algorithms and two feature sets:</p><ol><li>Logistic Regression + TF-IDF</li><li>Logistic Regression + Embeddings (<a href=https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 target=_blank>all-MiniLM-L6-v2</a>)</li><li>XGBoost + TF-IDF</li><li>XGBoost + Embeddings (<a href=https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 target=_blank>all-MiniLM-L6-v2</a>)</li></ol><p>For each model, we tracked the following metadata and artifacts on MLflow:</p><ul><li>Metadata<ul><li>Data source (dataset tags)</li><li>Algorithm/method used</li><li>Features used</li><li>Hyperparameter grid</li><li>Cross-validation config</li><li>Evaluation metrics (validation and testing)</li><li>Input datasets (schema and shape)</li></ul></li><li>Artifacts<ul><li>Serialized model with input/output signature</li><li>Python dependencies</li></ul></li></ul><p>We used the following two helper functions, at the beginning and end of our training function, which helped to keep the training code clean.</p><p>At the beginning of a run (training starting), we point to the correct MLflow server, create the experiment, if it doesn&rsquo;t exist, and start a run with a name based on the algorithm/method and feature set. Then, we use <code>mlflow.set_tags</code> to track metadata, including dataset based metadata, which is not yet visible in the current version of the MLflow UI when associated with a logged dataset directly. We also use <code>mlflow.log_inputs</code> to log the schema and size of the training and test sets. See next:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mlflow_start_run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>experiment_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>run_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tags</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>datasets</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=n>Dataset</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset_tags</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>tracking_uri</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>str</span><span class=p>(</span><span class=s2>&#34;MLFLOW_TRACKING_URI&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>set_tracking_uri</span><span class=p>(</span><span class=n>tracking_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow tracking URI: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>tracking_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>set_experiment</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow experiment: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>start_run</span><span class=p>(</span><span class=n>run_name</span><span class=o>=</span><span class=n>run_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow run: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>run_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow: logging tags and input datasets&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>set_tags</span><span class=p>(</span><span class=n>tags</span> <span class=o>|</span> <span class=n>dataset_tags</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>contexts</span> <span class=o>=</span> <span class=p>[</span><span class=n>ds</span><span class=o>.</span><span class=n>name</span> <span class=k>for</span> <span class=n>ds</span> <span class=ow>in</span> <span class=n>datasets</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>tags_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>dataset_tags</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=n>datasets</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_inputs</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>datasets</span><span class=o>=</span><span class=n>datasets</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contexts</span><span class=o>=</span><span class=n>contexts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>tags_list</span><span class=o>=</span><span class=n>tags_list</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>At the end of a run (training finished), we log the Python requirements, the serialized model, the best parameters from cross-validation (CV), and the metrics from CV and test set evaluation. See next:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mlflow_end_run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>:</span> <span class=n>Pipeline</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span> <span class=o>|</span> <span class=kc>None</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span> <span class=o>|</span> <span class=kc>None</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span> <span class=o>|</span> <span class=kc>None</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>signature</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>train</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow: inferring model signature&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>model_output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>train</span><span class=o>.</span><span class=n>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>signature</span> <span class=o>=</span> <span class=n>infer_signature</span><span class=p>(</span><span class=n>train</span><span class=o>.</span><span class=n>input</span><span class=p>,</span> <span class=n>model_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Extracting pip requirements from uv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pyproject</span> <span class=o>=</span> <span class=n>tomllib</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=s2>&#34;pyproject.toml&#34;</span><span class=p>,</span> <span class=s2>&#34;rb&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>requirements</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>pyproject</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;project&#34;</span><span class=p>,</span> <span class=p>{})</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;dependencies&#34;</span><span class=p>,</span> <span class=p>{})</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow: logging model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sk_model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>registered_model_name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>signature</span><span class=o>=</span><span class=n>signature</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>pip_requirements</span><span class=o>=</span><span class=n>requirements</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>params</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow: logging parameters&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow</span><span class=o>.</span><span class=n>log_params</span><span class=p>(</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>metrics</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;MLflow: logging metrics&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow</span><span class=o>.</span><span class=n>log_metrics</span><span class=p>(</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>end_run</span><span class=p>()</span>
</span></span></code></pre></div><h3 class="relative group">MLflow Artifact Storage<div id=mlflow-artifact-storage class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#mlflow-artifact-storage aria-label=Anchor>#</a></span></h3><p>MLflow uses a database, such as SQLite or PostgreSQL, as its backend store to log metadata. However, for artifacts, it can either log them locally (mostly just for testing), directly on S3, or by acting as an artifact proxy, transparently pointing to either a local or S3 backed location. Here&rsquo;s an overview on how to setup these two options, when starting MLflow:</p><ol><li>Direct S3 Storage<ul><li>Set <code>--default-artifacts-root</code> to an S3 path (e.g., <code>s3://mlflow/artifacts</code>).</li><li>Preferred when each user has its own AWS/S3 credentials.</li></ul></li><li>Artifact Proxy<ul><li>Set <code>--serve-artifacts</code>.</li><li>Set <code>--artifacts-destination</code> to a local or S3 path.</li><li>Artifacts will be stored under the default root of <code>mlflow-artifacts:/</code>.</li><li>Preferred when users have no direct interaction with AWS/S3, or to simplify model serving (no need to create S3 credentials for inference services).</li></ul></li></ol><p>Please see our <a href=https://github.com/DataLabTechTV/datalab/blob/v0.6.0/docker-compose.yml target=_blank>docker-compose.yml</a> file for details on setting up MLflow as an artifact proxy, with SQLite for the backend store. And also checkout the <a href=https://mlflow.org/docs/latest/ml/tracking/#tracking_setup target=_blank>Common Setups</a> section on the official documentation, where you&rsquo;ll be able to find a diagram of the three most common MLflow deployment options.</p><h2 class="relative group">Evaluation and Inferencing<div id=evaluation-and-inferencing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#evaluation-and-inferencing aria-label=Anchor>#</a></span></h2><p>We used a train/test split of 80/20, and then split our training set into 3-folds for validation. Our models were trained and optimized using cross-validation and F1 scoring over a minimal hyperparameter grid. For each model, we provided the accuracy and F1 score for the best fold, as well as for the test set. These were logged into MLflow, as described above.</p><p>Out of the four models, we selected the best model, which was XGBoost + Embeddings, along with the most different model, Logistic Regression + TF-IDF, and served these models through a unique endpoint, randomly selecting one of them per request, for A/B testing.</p><p>Each inference was assigned a UUID and a creation date, and then sent to a Kafka topic. A topic consumer buffered these requests until hitting a large enough batch or a given timeout, at which point they were flushed into a DuckLake catalog with encrypted storage (remember, this is user data). An example of how to call this endpoint is provided in the <code>justfile</code>:</p><pre tabindex=0><code class=language-just data-lang=just>mlops_test_inference_payload := &#39;&#39;&#39;
{
    &#34;models&#34;: [
        {
            &#34;name&#34;: &#34;dd_logreg_tfidf&#34;,
            &#34;version&#34;: &#34;latest&#34;
        },
        {
            &#34;name&#34;: &#34;dd_xgboost_embeddings&#34;,
            &#34;version&#34;: &#34;latest&#34;
        }
    ],
    &#34;data&#34;: &#34;...bc i have depression how are you all d&#34;,
    &#34;log_to_lakehouse&#34;: true
}
&#39;&#39;&#39;

mlops-test-inference: check-curl
    curl -f -X POST &#34;http://localhost:8000/inference&#34; \
        -H &#34;Content-Type: application/json&#34; \
        -d &#39;{{mlops_test_inference_payload}}&#39;
    @echo
    curl -f -X GET &#34;http://localhost:8000/inference/logs/flush&#34;
</code></pre><p>We also provided an API endpoint where users were able to submit a feedback score (1.0 or 0.0 for our depression classifier), based on the inference UUID. Multiple requests with the same inference UUID appended the feedback to the <code>feedback DOUBLE[]</code> column.</p><h2 class="relative group">Deployment<div id=deployment class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#deployment aria-label=Anchor>#</a></span></h2><p>Below, we cover two approaches for model deployment:</p><ol><li>Using MLflow to build a Docker image per model.</li><li>Building your own custom FastAPI REST endpoint.</li></ol><p>The MLflow approach provides a more straightforward and standard way to deploy, but each model requires its own separate deployment, and you can&rsquo;t control the outputfor example, if you want to return the output from <code>predict_proba</code> for a scikit-learn model, instead of using <code>predict</code>, then you&rsquo;d need to code that into your model&rsquo;s prediction function before logging it to MLflow.</p><p>The custom approach provides more flexibility and potential for optimizationfor example, we can share resources for multiple models, or build a custom environment with minimal dependencies. Moreover, we can still create our own Docker image for a custom REST endpoint. This is the preferred approach by seasoned ML Engineers, and this is what we do here as well, even more so since our inference results return probabilities and need to be logged to DuckLake via Kafka.</p><h3 class="relative group">MLflow Models<div id=mlflow-models class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#mlflow-models aria-label=Anchor>#</a></span></h3><p>While MLflow provides an out-of-the-box approach to deploy logged models, the Docker images it produces tends to be huge by default (~25 GB for the <code>datalab</code> project). You&rsquo;ll need to properly determine the minimum required dependencies when logging your model, if you want to make sure that the resulting image size is optimized. Even then, this deployment approach will produce individual images per model, which is good for isolation, but harder on resource management and cost. Instead, you might want to build your own custom solution for deployment, which we will describe in the following section. Meanwhile, here&rsquo;s an example on how to use the MLflow&rsquo;s deployment workflow.</p><p>In order to create a Docker image for your model, you can simply run the following command, providing it a model URI and the target image name:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mlflow models build-docker <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	-m <span class=s2>&#34;models:/dd_logreg_tfidf/latest&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	-n <span class=s2>&#34;mlflow_model_dd_logreg_tfidf&#34;</span>
</span></span></code></pre></div><p>You can then run a container based on the produced image, optionally limiting the number of workers (which defaults to all CPU cores) by setting <code>MLFLOW_MODEL_WORKERS</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run -d <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	-p 5001:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	-e <span class=nv>MLFLOW_MODELS_WORKERS</span><span class=o>=</span><span class=m>4</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	<span class=s2>&#34;mlflow_model_dd_logreg_tfidf&#34;</span>
</span></span></code></pre></div><p>In order to classify a batch of examples for a model that takes a DataFrame with a single column <code>input</code>, you can <code>POST</code> JSON to the <code>/invocations</code> path:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -X POST <span class=s2>&#34;http://localhost:5001/invocations&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	-H <span class=s2>&#34;Content-Type: application/json&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	-d <span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>			&#34;dataframe_split&#34;: {
</span></span></span><span class=line><span class=cl><span class=s1>				&#34;columns&#34;: [&#34;input&#34;],
</span></span></span><span class=line><span class=cl><span class=s1>				&#34;data&#34;: [
</span></span></span><span class=line><span class=cl><span class=s1>					[&#34;...bc i have depression how are you all d&#34;],
</span></span></span><span class=line><span class=cl><span class=s1>					[&#34;...we were really so lucky...&#34;]
</span></span></span><span class=line><span class=cl><span class=s1>				]
</span></span></span><span class=line><span class=cl><span class=s1>			}
</span></span></span><span class=line><span class=cl><span class=s1>		}&#39;</span>
</span></span></code></pre></div><h3 class="relative group">Custom API<div id=custom-api class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#custom-api aria-label=Anchor>#</a></span></h3><p>Like we said, in practice, it&rsquo;s more common to deploy models using a custom REST API, usually created with FastAPI, often chosen due to its self-documenting approach via <a href=https://swagger.io/tools/swagger-ui/ target=_blank>Swagger UI</a> and <a href=https://github.com/Redocly/redoc target=_blank>ReDoc</a>. This also lets you produce your own Docker image, optimizing it as much as you&rsquo;d like, and you can also serve multiple models using the same API, which you cannot do with the MLflow approach.</p><p>Imagine a 25 GiB image for each of your classifiers, the time it would take to build and deploy, and the resources it would require! This is why most ML Engineers create their own web services to deploy their models.</p><p>Our API provides the following two main endpoints, which encapsulate the whole workflow logic.</p><p><code>POST /inference</code> to <code>INSERT</code> inference results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@app.post</span><span class=p>(</span><span class=s2>&#34;/inference&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>inference</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>inference_request</span><span class=p>:</span> <span class=n>InferenceRequest</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>request</span><span class=p>:</span> <span class=n>Request</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>inference_result</span> <span class=o>=</span> <span class=n>predict</span><span class=p>(</span><span class=n>inference_request</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=n>ModelNotFound</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>JSONResponse</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=s2>&#34;Model not found&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>status_code</span><span class=o>=</span><span class=n>status</span><span class=o>.</span><span class=n>HTTP_404_NOT_FOUND</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>inference_request</span><span class=o>.</span><span class=n>log_to_lakehouse</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Queuing lakehouse insertion for inference result&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>await</span> <span class=n>queue_inference_result</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>request</span><span class=o>.</span><span class=n>app</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>inference_result_producer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>inference_result</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>inference_result</span>
</span></span></code></pre></div><p><code>PATCH /inference</code> to <code>UPDATE</code> an inference result by appending to its <code>feedback</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@app.patch</span><span class=p>(</span><span class=s2>&#34;/inference&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>inference</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>inference_feedback</span><span class=p>:</span> <span class=n>InferenceFeedback</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>request</span><span class=p>:</span> <span class=n>Request</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>log</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Queuing lakehouse append for inference feedback&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>await</span> <span class=n>queue_inference_feedback</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>request</span><span class=o>.</span><span class=n>app</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>inference_feedback_producer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>inference_feedback</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Response</span><span class=p>(</span><span class=n>status_code</span><span class=o>=</span><span class=n>status</span><span class=o>.</span><span class=n>HTTP_204_NO_CONTENT</span><span class=p>)</span>
</span></span></code></pre></div><h2 class="relative group">Monitoring Strategy<div id=monitoring-strategy class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#monitoring-strategy aria-label=Anchor>#</a></span></h2><p>During monitoring, we compare reference data with the current data. Our reference data is always based on the training set (e.g., prediction labels or features based on the training set). Our current data, on the other hand, is based on a sliding window of 7 days, that we compute per day.</p><p>Below, we will describe the metrics that we considered, along with our particular implementation, which you can find in the <a href=https://github.com/DataLabTechTV/datalab/blob/v0.6.0/ml/monitor.py target=_blank>datalab</a> codebase, under <code>ml.monitor</code>.</p><h3 class="relative group">Prediction Drift<div id=prediction-drift class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#prediction-drift aria-label=Anchor>#</a></span></h3><p>Prediction drift, or concept drift, is concerned with comparing the reference and current prediction probability distributions.</p><p>While there are multiple possible statistical approaches to compare these distributions, we use a KolmogorovSmirnov test, particularly looking at the D-statistic, which illustrates the largest possible gap between the two distributions. The higher the D-statistic, the higher the prediction drift.</p><h3 class="relative group">Feature Drift<div id=feature-drift class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#feature-drift aria-label=Anchor>#</a></span></h3><p>Feature drift, or data drift, is usually concerned with comparing the distributions of individual features. Drift scores for individual features can be aggregated into a global feature drift score, but feature drift can also be computed over all the feature set directly. Below, we briefly explain both approaches, per feature or dataset.</p><h4 class="relative group">Per Feature<div id=per-feature class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#per-feature aria-label=Anchor>#</a></span></h4><p>We start by comparing each feature individually for the reference and current datasets. For example, if our features are text, we might compare term distributions or the distributions of TF-IDF over all examples. If we&rsquo;re working with embeddings, it&rsquo;s similarassuming rows are examples and columns are features, we simply compare equivalent columns on the reference and current data.</p><p>Again, there are several statistical approaches that we can use here, but let&rsquo;s assume we&rsquo;re again working with a KolmogorovSmirnov test, which provides the D-statistic, as well as the p-value.</p><p>Once we compare all pairs of features, we&rsquo;ll end up with a 1D array with a score per feature. If this score is the D-statistic, it&rsquo;s common for us to take the median, which is less sensitive to outliers, and compute an aggregate feature drift score. Another, less informative, approach is to count the number of p-values &lt; 0.05 and return that fraction, which just tells us how many features drifted significantly, thus imputing drift to the overall data.</p><p>This is not our implementation here. Instead, we relied on a per dataset feature drift, as described next.</p><h4 class="relative group">Per Dataset<div id=per-dataset class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#per-dataset aria-label=Anchor>#</a></span></h4><p>For this approach, all features are used simultaneously. A simple way to achieve this is by concatenating reference and current data, assigning each subset its own label:</p><ul><li>Reference  0</li><li>Current  1</li></ul><p>Keep in mind that these are not the labels in your original data, so, for example, our depression training set contained label 0 for not depression and label 1 for depression, but here the whole dataset will have label 0, regardless of whether we&rsquo;re considering a negative or positive example of depression. Now, instead, we&rsquo;re trying to distinguish between examples in reference or current.</p><p>After training a simple classifier (e.g., logistic regression) with the described dataset, we evaluate using ROC AUC.</p><ul><li>If AUC ~ 0.5, the classifier is no better than random guessing, so it cannot distinguish between the datasets, which means there is no feature drift.</li><li>If AUC > 0.5, the classifier is able to distinguish both datasets, so they are not the same and there is as much drift as the AUC.</li><li>If AUC &lt; 0.5, the interpretation is similar to that of AUC > 0.5 in regards to drift, but it also tells us that the classifier is predicting in reverse (this should never happen).</li></ul><h3 class="relative group">Estimated Performance<div id=estimated-performance class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#estimated-performance aria-label=Anchor>#</a></span></h3><p>Inspired by <a href=https://nannyml.readthedocs.io/en/v0.10.3/index.html target=_blank>NannyML</a>, which was incompatible with our remaining dependencies, we implemented confidence-based performance estimation (CBPE).</p><p>For the model we want to test (e.g., logistic regression with TF-IDF features), we train an isotonic regression model to predict correctness based on the output probabilities of the model we&rsquo;re testing. The isotonic regressor is trained over a dataset with a single feature in the format:</p><p>$\text{pred_prob} \mapsto (\text{pred_label} = \text{correct_label})$</p><p>Where $\text{pred_prob}$ is the output of <code>predict_proba</code> for the model we&rsquo;re testing, over examples in the original training set, $\text{pred_label}$ is the corresponding binary output after applying the decision threshold (e.g., $\text{pred_label} \leftarrow \text{pred_prob} \ge 0.5$), and $\text{correct_label}$ is the target on the original training set, used to train the model we&rsquo;re testing.</p><p>Once we have the isotonic regressor (one per model to test), we&rsquo;re be able to predict the inference correctness for new unseen examples, and, from that, we&rsquo;re then able to obtain true and false positives and negatives, and calculate evaluation metrics like accuracy or F1.</p><h3 class="relative group">User Feedback<div id=user-feedback class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#user-feedback aria-label=Anchor>#</a></span></h3><p>Finally, based on user feedback, we&rsquo;re also able to a calculate Brier score per inference result, comparing our binary prediction to a probabilistic user feedback score. We can then average the Brier scores to obtain a global error-like metric (notice the similarity with mean-squared error, MSE):</p><p>$\displaystyle\text{Avg}(BS) = \frac{1}{n}\sum_{i=1}^n\left(\text{prediction}_i - \frac{1}{m}\sum_{j=1}^m\text{feedback}_{ij}\right)$</p><p>Where:</p><ul><li>$\text{prediction}_i \in \{0, 1\}$</li><li>$\text{feedback}_{ij} \in [0, 1]$.</li></ul><p>Similarly to MSE, a lower average Brier score is better:</p><ul><li>0 is a perfect calibration.</li><li>1 is the worst possible outcome.</li></ul><h3 class="relative group">Extending Observability<div id=extending-observability class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#extending-observability aria-label=Anchor>#</a></span></h3><p>Other elements that we might track to extend observability would be:</p><ul><li>Data Quality<ul><li>Shared responsibility with data engineering.</li><li>Rule-based validations (e.g., check for all zeros in predictions, or missing values).</li><li>For example, expressed as an aggregate score of rule compliance.</li></ul></li><li>Model Explainability<ul><li><a href=https://shap.readthedocs.io/en/latest/ target=_blank>SHAP</a> (SHapley Additive exPlanations)</li><li><a href=https://github.com/marcotcr/lime target=_blank>LIME</a> (Local Interpretable Model-agnostic Explanations)</li></ul></li></ul><h2 class="relative group">Simulating Inference and Feedback<div id=simulating-inference-and-feedback class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#simulating-inference-and-feedback aria-label=Anchor>#</a></span></h2><p>Since we do not have a production system, we simulate inference requests and user feedback, in order to obtain credible data to test our monitoring statistics with. We use a dataset external to our train/test set, also from Hugging Face, to help with this task: <a href=https://huggingface.co/datasets/joangaes/depression target=_blank>joangaes/depression</a>. We call this our monitor set. This follows a similar structure to the train/test set, with a text column and a label column for depression or not depression.</p><p>Using this data, we simulate inference and feedback assignment in multiple passes (default 3) over the monitor set, where we:</p><ol><li>Sample a fraction of the dataset (optional).</li><li>Run inference over all examples using a given decision threshold (default 0.5).</li><li>Log results to the data lakehouse with a random date (default range of 4 weeks).</li><li>Provide feedback for a fraction (default range of $[0.45, 0.55]$) of those results&mldr;</li><li>&mldr;simulating wrong feedback by using the complement over a fraction of feedback outputs (default range of $[0.10, 0.25]$) of the considered results.</li></ol><p>Simulated data should contain mostly correct feedback, with a few errors, simulating a real-world scenario. Inferences might have no feedback, or any number of feedback scores up to the number of passes, i.e., 0 to 3 feedback scores.</p><h2 class="relative group">A/B Testing Results<div id=ab-testing-results class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ab-testing-results aria-label=Anchor>#</a></span></h2><p>Based on the simulated inference results and user feedback, we now look at and interpret the monitoring statistics.</p><h3 class="relative group">Inferences Over Time<div id=inferences-over-time class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#inferences-over-time aria-label=Anchor>#</a></span></h3><p>We track the number of inferences ran per day, over the simulated period of one month. This also shows how many times each model was randomly selected per day. Volume is higher for mid-August and although model selection is uniform, the logistic regression model using TF-IDF features seems to have been selected more frequently when looking at daily aggregations.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./count.png alt="Number of Inferences Over Time"></figure></p><h3 class="relative group">Prediction Drift<div id=prediction-drift-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#prediction-drift-1 aria-label=Anchor>#</a></span></h3><p>Also known as concept drift, we measure prediction drift based on the D-statistic from the KolmogorovSmirnov test. The lower the D-statistic, the less prediction drift there is. As we can see, prediction drift is reaching critical levels for the logistic regression model, while being much lower for the XGBoost model, despite still showing a considerable magnitude. However, the logistic regression is particularly concerning, as the D-statistic is not only high, but also extremely consistent over time, indicating an issue with that model, beyond just optimization.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./pred_drift.png alt="Prediction Drift"></figure></p><h3 class="relative group">Feature Drift<div id=feature-drift-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#feature-drift-1 aria-label=Anchor>#</a></span></h3><p>Also known as data drift, feature drift is measured based on ROC AUC. As such, we are looking for values of ~0.5, indicating no feature drift. As we can see, there is also considerable feature drift for both models. This indicates that the training data was not representative of incoming examples for inference. It might also be the case that data preprocessing requires a few normalization steps to make sure the text is formatted similarly across reference and current data. For our models, we&rsquo;re probably suffering from both problems, as we didn&rsquo;t put much effort into the preprocessing stage. This goes to show the importance of good data engineering.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./feat_drift.png alt="Feature Drift"></figure></p><h3 class="relative group">Estimated Performance<div id=estimated-performance-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#estimated-performance-1 aria-label=Anchor>#</a></span></h3><p>While previous metrics indicate that our models are not properly calibrated, we&rsquo;re still predicting evaluation scores as high as the ones obtained during testing. On one side, this matches expected behavior, on the other side we know that we have other problems to solve, before we can trust this score overall.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./e_f1.png alt="Estimated F1 Score"></figure></p><h3 class="relative group">User Feedback<div id=user-feedback-1 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#user-feedback-1 aria-label=Anchor>#</a></span></h3><p>Finally, based on user feedback, we&rsquo;re obtaining inconsistent average Brier scores over time, most likely due to the small monitor set sample that we used. However, overall, the lowest (best) values seem to be for the XGBoost model, indicating we might obtain better results by investing on that model, but we&rsquo;d need more information.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=./user_brier.png alt="Average User Feedback Brier Score"></figure></p><h2 class="relative group">Final Remarks<div id=final-remarks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#final-remarks aria-label=Anchor>#</a></span></h2><p>Hopefully, this is enough to get you started on MLOps and ML Engineering, providing a comprehensible example of an end-to-end workflow and the types of tasks we&rsquo;re expected to work on as an ML Engineer. In future videos and blog posts, I expect to go deeper into the infrastructure side of Data Engineering and MLOps, moving into model deployment, and real-time model monitoring.</p></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Data Lab Tech" src=/img/avatar_hu14365428751860151861.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Data Lab Tech</div><div class="text-sm text-neutral-700 dark:text-neutral-400"><a href=https://youtube.com/@DataLabTechTV target=_blank>https://youtube.com/@DataLabTechTV</a></div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://youtube.com/@DataLabTechTV target=_blank aria-label=Youtube rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78.0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://bsky.app/profile/datalabtechtv.com target=_blank aria-label=Bluesky rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/DataLabTechTV target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://discord.gg/6xpe827ANZ target=_blank aria-label=Discord rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M524.531 69.836a1.5 1.5.0 00-.764-.7A485.065 485.065.0 00404.081 32.03a1.816 1.816.0 00-1.923.91 337.461 337.461.0 00-14.9 30.6 447.848 447.848.0 00-134.426.0 309.541 309.541.0 00-15.135-30.6 1.89 1.89.0 00-1.924-.91A483.689 483.689.0 00116.085 69.137a1.712 1.712.0 00-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016.0 00.765 1.375A487.666 487.666.0 00176.02 479.918a1.9 1.9.0 002.063-.676A348.2 348.2.0 00208.12 430.4a1.86 1.86.0 00-1.019-2.588 321.173 321.173.0 01-45.868-21.853 1.885 1.885.0 01-.185-3.126c3.082-2.309 6.166-4.711 9.109-7.137a1.819 1.819.0 011.9-.256c96.229 43.917 200.41 43.917 295.5.0a1.812 1.812.0 011.924.233c2.944 2.426 6.027 4.851 9.132 7.16a1.884 1.884.0 01-.162 3.126 301.407 301.407.0 01-45.89 21.83 1.875 1.875.0 00-1 2.611 391.055 391.055.0 0030.014 48.815 1.864 1.864.0 002.063.7A486.048 486.048.0 00610.7 405.729a1.882 1.882.0 00.765-1.352C623.729 277.594 590.933 167.465 524.531 69.836zM222.491 337.58c-28.972.0-52.844-26.587-52.844-59.239S193.056 219.1 222.491 219.1c29.665.0 53.306 26.82 52.843 59.239.0 32.654-23.41 59.241-52.843 59.241zm195.38.0c-28.971.0-52.843-26.587-52.843-59.239S388.437 219.1 417.871 219.1c29.667.0 53.307 26.82 52.844 59.239.0 32.654-23.177 59.241-52.844 59.241z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:mail@datalabtechtv.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></span></a></div></div></div></div><div class=mb-10></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://datalabtechtv.com/posts/mlops-ab-testing/&amp;title=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://bsky.app/intent/compose?text=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake+https://datalabtechtv.com/posts/mlops-ab-testing/" title="Post on Bluesky" aria-label="Post on Bluesky"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 232.562c-21.183-41.196-78.868-117.97-132.503-155.834-51.378-36.272-70.978-29.987-83.828-24.181-14.872 6.72-17.577 29.554-17.577 42.988.0 13.433 7.365 110.138 12.169 126.281 15.873 53.336 72.376 71.358 124.413 65.574 2.66-.395 5.357-.759 8.089-1.097-2.68.429-5.379.796-8.089 1.097-76.259 11.294-143.984 39.085-55.158 137.972C201.224 526.527 237.424 403.67 256 341.379c18.576 62.291 39.972 180.718 150.734 83.983 83.174-83.983 22.851-126.674-53.408-137.969-2.71-.302-5.409-.667-8.089-1.096 2.732.337 5.429.702 8.089 1.096 52.037 5.785 108.54-12.239 124.413-65.574 4.804-16.142 12.169-112.847 12.169-126.281.0-13.434-2.705-36.267-17.577-42.988-12.85-5.806-32.45-12.09-83.829 24.181C334.868 114.595 277.183 191.366 256 232.562z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://s2f.kytta.dev/?text=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake%20https://datalabtechtv.com/posts/mlops-ab-testing/" title aria-label><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48.0.0.0-63.72 28.5-63.72 125.7.0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54.0 01-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://reddit.com/submit/?url=https://datalabtechtv.com/posts/mlops-ab-testing/&amp;resubmit=true&amp;title=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake" title="Submit to Reddit" aria-label="Submit to Reddit"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M201.5 305.5c-13.8.0-24.9-11.1-24.9-24.6.0-13.8 11.1-24.9 24.9-24.9 13.6.0 24.6 11.1 24.6 24.9.0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4.0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7.0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9.0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5.0 52.6 59.2 95.2 132 95.2 73.1.0 132.3-42.6 132.3-95.2.0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6.0-2.2-2.2-6.1-2.2-8.3.0-2.5 2.5-2.5 6.4.0 8.6 22.8 22.8 87.3 22.8 110.2.0 2.5-2.2 2.5-6.1.0-8.6-2.2-2.2-6.1-2.2-8.3.0zm7.7-75c-13.6.0-24.6 11.1-24.6 24.9.0 13.6 11.1 24.6 24.6 24.6 13.8.0 24.9-11.1 24.9-24.6.0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.facebook.com/sharer/sharer.php?u=https://datalabtechtv.com/posts/mlops-ab-testing/&amp;quote=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake" title="Share on Facebook" aria-label="Share on Facebook"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://datalabtechtv.com/posts/mlops-ab-testing/&amp;subject=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://api.whatsapp.com/send?text=https://datalabtechtv.com/posts/mlops-ab-testing/&amp;resubmit=true&amp;title=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake" title="Share via WhatsApp" aria-label="Share via WhatsApp"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4.0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3.0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2.0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2.0-101.7 82.8-184.5 184.6-184.5 49.3.0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5.0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8s-14.3 18-17.6 21.8c-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2s-9.7 1.4-14.8 6.9c-5.1 5.6-19.4 19-19.4 46.3.0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://t.me/share/url?url=https://datalabtechtv.com/posts/mlops-ab-testing/&amp;resubmit=true&amp;title=MLOps:%20A/B%20Testing%20with%20MLflow,%20Kafka,%20and%20DuckLake" title="Share via Telegram" aria-label="Share via Telegram"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M248 8C111.033 8 0 119.033.0 256S111.033 504 248 504 496 392.967 496 256 384.967 8 248 8zM362.952 176.66c-3.732 39.215-19.881 134.378-28.1 178.3-3.476 18.584-10.322 24.816-16.948 25.425-14.4 1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25 5.342-39.5 3.652-3.793 67.107-61.51 68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608 69.142-14.845 10.194-26.894 9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7 18.45-13.7 108.446-47.248 144.628-62.3c68.872-28.647 83.183-33.623 92.511-33.789 2.052-.034 6.639.474 9.61 2.885a10.452 10.452.0 013.53 6.716A43.765 43.765.0 01362.952 176.66z"/></svg></span></a></section></div><script>var oid="views_posts/mlops-ab-testing/index.md",oid_likes="likes_posts/mlops-ab-testing/index.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/posts/economic-competition-networks/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Economic Competition Networks</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-08-06T17:00:00+01:00>6 August 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/posts/data-lab-infra-architecture/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Data Lab Infra - Part 1: Architecture Design</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-09-16T12:00:00+01:00>16 September 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 mt-8 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/privacy/ title>Privacy</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/cookies/ title>Cookies</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a id=reset-cookie-options class="decoration-primary-500 flex items-center" href=# title="Reset Cookie Options"><span class=mr-1></span></a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2026
Data Lab Tech</p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script><script src=/js/search-keybind.min.b0547e1bcfb3922a05d78728999bbd36902e6c52a31b0b1efa373df47c6fa095.js integrity="sha256-sFR+G8+zkioF14comZu9NpAubFKjGwse+jc99HxvoJU=" crossorigin=anonymous></script><script src=/js/cookie-banner.min.010e183607b0d0550c6b0c6cdfee0ef6a8251e4995f06db7c9541c7a847f9751.js integrity="sha256-AQ4YNgew0FUMawxs3+4O9qglHkmV8G23yVQceoR/l1E=" crossorigin=anonymous></script><div id=cookie-spacer class="h-12 hidden"></div><div id=cookie-banner class="fixed inset-x-0 bottom-0 z-[90] hidden"><div class="opacity-90 backdrop-blur-2xl shadow-2xl px-4 py-4 text-sm text-white dark:text-neutral-100"><div class="max-w-[64rem] mx-auto flex flex-wrap items-center justify-between gap-4"><span>We use cookies to enhance your experience.
<a href=/privacy/ class="underline text-blue-300 hover:text-blue-100 ml-1">Learn more</a>.</span><div class="flex gap-4 shrink-0"><button id=cookie-decline class="font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400 cursor-pointer">
Decline
</button>
<button id=cookie-accept class="font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400 cursor-pointer">
Accept</button></div></div></div></div><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
    mermaid.initialize({
        startOnLoad: true,
        theme: "base",
        themeCSS: `
          /* Left-align text in class diagrams */
          .nodeLabel {
            text-wrap: nowrap;
          }
        `,
        flowchart: {
            nodeSpacing: 20,
            rankSpacing: 100,
        },
        themeVariables: {
            fontFamily: 'var(--default-mono-font-family, ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace)',
            fontSize: "1.5em",

            background: "#1e1e1e",
            textColor: "#f8fafc",
            primaryColor: "#0ea5e9",
            tertiaryColor: "#f8fafc",
            primaryTextColor: "#1e1e1e",
            lineColor: "#94a3b8",
            noteBkgColor: "#2c3a4a",

             
            nodeBorder: "#38bdf8",
            clusterBkg: "#2c3a4a",
            clusterBorder: "#4b5563",

             
            actorTextColor: "#f8fafc",
            loopTextColor: "#f8fafc",

             
            tagLabelFontSize: ".6em",
            commitLabelFontSize: ".6em",
            commitLabelColor: "#f8fafc",
            commitLabelBackground: "#2c3a4a",
            git0: "#0ea5e9",
            git1: "#4b5563",
        }
    });
</script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://datalabtechtv.com/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>